{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import ctypes\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14541\n",
      "237\n",
      "272115\n",
      "17535\n",
      "20466\n",
      "2721\n"
     ]
    }
   ],
   "source": [
    "# 使用 GPU 的设置\n",
    "use_gpu = True if torch.cuda.is_available() else False\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "\n",
    "class Config():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.dim = 30\n",
    "        self.dim1 = 5\n",
    "        self.dim2 = self.dim // self.dim1\n",
    "        \n",
    "        # config of training\n",
    "        self.learning_rate = 0.01\n",
    "        self.batch_num = 100\n",
    "        self.epoch_num = 1000\n",
    "        self.lmbda = 0.3\n",
    "        self.opt_method = \"Adagrad\"\n",
    "        \n",
    "        # config of model storage\n",
    "        self.vali_epoch = 500\n",
    "        self.save_epoch = 500\n",
    "        self.mode = \"train\"        # \"train\" or \"test\"\n",
    "        self.checkpoint_path = \"./checkpoints\"\n",
    "        \n",
    "        # 调用 C++ 封装的库文件 Base.io\n",
    "        self.clib = ctypes.cdll.LoadLibrary(\"./Base.so\")\n",
    "        self.dataset = \"FB15K237\"    # \"WN18\" or \"WN18RR\" or \"FB15K\" or \"FB15K237\"\n",
    "        self.in_path = \"./\" + self.dataset + \"/\"    # 将数据集路径传递给 Base.io\n",
    "\n",
    "        # negative sampling\n",
    "        self.clib.sampling.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_int64,\n",
    "            ctypes.c_int64,\n",
    "            ctypes.c_int64,\n",
    "        ]\n",
    "        \n",
    "        # validation dataset\n",
    "        self.clib.getValidHeadBatch.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "        ]\n",
    "        self.clib.getValidTailBatch.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "        ]\n",
    "        self.clib.validHead.argtypes = [ctypes.c_void_p]\n",
    "        self.clib.validTail.argtypes = [ctypes.c_void_p]\n",
    "        \n",
    "        # link prediction test dataset\n",
    "        self.clib.getHeadBatch.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "        ]\n",
    "        self.clib.getTailBatch.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "        ]\n",
    "        self.clib.testHead.argtypes = [ctypes.c_void_p]\n",
    "        self.clib.testTail.argtypes = [ctypes.c_void_p]\n",
    "        \n",
    "        self.test_file = \"\"\n",
    "        self.clib.setInPath(ctypes.create_string_buffer(self.in_path.encode(), len(self.in_path)*2))\n",
    "        self.clib.setTestFilePath(ctypes.create_string_buffer(self.test_file.encode(), len(self.test_file)*2))\n",
    "        \n",
    "        self.clib.setBern(0)\n",
    "        self.clib.setWorkThreads(8)\n",
    "        self.clib.randReset()\n",
    "        \n",
    "        self.clib.importTrainFiles()\n",
    "        self.clib.importTestFiles()\n",
    "        self.clib.importTypeFiles()\n",
    "        \n",
    "        # 数据集统计信息\n",
    "        self.ent_num = self.clib.getEntityTotal()\n",
    "        self.rel_num = self.clib.getRelationTotal()\n",
    "        self.train_num = self.clib.getTrainTotal()\n",
    "        self.vali_num = self.clib.getValidTotal()\n",
    "        self.test_num = self.clib.getTestTotal()\n",
    "        \n",
    "        self.batch_size = int(self.train_num / self.batch_num)\n",
    "        \n",
    "con = Config()\n",
    "print(con.ent_num)\n",
    "print(con.rel_num)\n",
    "print(con.train_num)\n",
    "print(con.vali_num)\n",
    "print(con.test_num)\n",
    "print(con.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(237, 30)\n"
     ]
    }
   ],
   "source": [
    "# 为 CPU 设置用于生成随机数的种子，以使得结果是确定的\n",
    "torch.manual_seed(123)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(123)    # 使用多个 GPU 的话，为所有的 GPU 设置种子，torch.cuda.manual_seed() 是为当前 GPU 设置种子\n",
    "    \n",
    "class Conv3D(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(Conv3D, self).__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        self.batch_h = None\n",
    "        self.batch_t = None\n",
    "        self.batch_r = None\n",
    "        self.batch_y = None\n",
    "        \n",
    "        self.ent_embeddings = nn.Embedding(self.config.ent_num, self.config.dim)\n",
    "        self.rel_embeddings = nn.Embedding(self.config.rel_num, self.config.dim)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm3d(num_features=1)\n",
    "        self.bn2 = nn.BatchNorm3d(num_features=64)\n",
    "        self.conv_layer = nn.Conv3d(in_channels=1, out_channels=64, kernel_size=(3,1,2))\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.nonlinear = nn.ReLU()\n",
    "        self.conv_size = 64*(3-3+1)*(self.config.dim1-1+1)*(self.config.dim2-2+1)\n",
    "        self.fc_layer = nn.Linear(in_features=self.conv_size, out_features=1)\n",
    "        \n",
    "        self.criterion = nn.Softplus()\n",
    "        \n",
    "        # 初始化 embeddings 以及卷积层、全连接层的参数\n",
    "        nn.init.xavier_uniform_(self.ent_embeddings.weight.data)\n",
    "        nn.init.xavier_uniform_(self.rel_embeddings.weight.data)\n",
    "        nn.init.xavier_uniform_(self.conv_layer.weight.data)\n",
    "        nn.init.xavier_uniform_(self.fc_layer.weight.data)\n",
    "        \n",
    "        \n",
    "    def cal_score(self):\n",
    "        h = self.ent_embeddings(self.batch_h)\n",
    "        r = self.rel_embeddings(self.batch_r)\n",
    "        t = self.ent_embeddings(self.batch_t)\n",
    "        \n",
    "        h = h.view(-1, 1, self.config.dim1, self.config.dim2)\n",
    "        r = r.view(-1, 1, self.config.dim1, self.config.dim2)\n",
    "        t = t.view(-1, 1, self.config.dim1, self.config.dim2)\n",
    "        cube = torch.cat([h,r,t], 1)\n",
    "        \n",
    "        x = cube.unsqueeze(1)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv_layer(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = x.view(-1, self.conv_size)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_layer(x)\n",
    "        \n",
    "        score = x.view(-1)\n",
    "        return -score\n",
    "        \n",
    "    def forward(self):\n",
    "        batch_score = self.cal_score()\n",
    "        \n",
    "        h = self.ent_embeddings(self.batch_h)\n",
    "        r = self.rel_embeddings(self.batch_r)\n",
    "        t = self.ent_embeddings(self.batch_t)\n",
    "        \n",
    "        # l2_regular = h.norm(2) + r.norm(2) + t.norm(2)\n",
    "        l2_regular = torch.mean(h ** 2) + torch.mean(r ** 2) + torch.mean(t ** 2)\n",
    "        \n",
    "        for p in self.conv_layer.parameters():\n",
    "            l2_regular += p.norm(2)\n",
    "        for p in self.fc_layer.parameters():\n",
    "            l2_regular += p.norm(2)\n",
    "        \n",
    "        mean = torch.mean(self.criterion(self.batch_y * batch_score))\n",
    "        regular = self.config.lmbda * l2_regular\n",
    "        # print(mean, regular)\n",
    "        return mean + regular\n",
    "    \n",
    "conv3d = Conv3D(con)\n",
    "conv3d.batch_h = torch.LongTensor([1,40,5,4,6,79])\n",
    "conv3d.batch_r = torch.LongTensor([5,4,2,4,1,9])\n",
    "conv3d.batch_t = torch.LongTensor([3,60,80,3,56,7])\n",
    "conv3d.batch_y = torch.LongTensor([1,1,1,-1,-1,-1])\n",
    "conv3d()\n",
    "print(conv3d.rel_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    \n",
    "    def __init__(self, config, model):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.clib = self.config.clib\n",
    "        \n",
    "    def set_model(self, mode = 'train'):\n",
    "        self.model.to(device)\n",
    "        \n",
    "        if mode == 'train':    # 训练模型\n",
    "            print(\"Initializing training model...\")\n",
    "            # 为训练模型设定优化器\n",
    "            if self.config.opt_method == \"Adagrad\":\n",
    "                self.optimizer = optim.Adagrad(\n",
    "                    params = self.model.parameters(),\n",
    "                    lr = self.config.learning_rate,\n",
    "                    lr_decay = 0,\n",
    "                    weight_decay = 0\n",
    "                )\n",
    "            elif self.config.opt_method == \"Adadelta\":\n",
    "                self.optimizer = optim.Adadelta(\n",
    "                    params = self.model.parameters(),\n",
    "                    lr = self.config.learning_rate,\n",
    "                    weight_decay = 0\n",
    "                )\n",
    "            elif self.config.opt_method == \"Adam\":\n",
    "                self.optimizer = optim.Adam(\n",
    "                    params = self.model.parameters(),\n",
    "                    lr = self.config.learning_rate,\n",
    "                    weight_decay = 0\n",
    "                )\n",
    "            else:    # 不是以上三种的话就用 SGD\n",
    "                self.optimizer = optim.SGD(\n",
    "                    params = self.model.parameters(),\n",
    "                    lr = self.config.learning_rate,\n",
    "                    weight_decay = 0\n",
    "                )\n",
    "            print(\"Training model has been initialized.\")\n",
    "        else:                           # mode == 'test'，从 checkpoints 中载入模型，用于测试\n",
    "            print(\"Fetching model for test...\")\n",
    "            ckpt_path = os.path.join(\"./checkpoints/\", self.config.dataset + \"-netparam_best\" + \".ckpt\")  \n",
    "            self.model.load_state_dict(torch.load(ckpt_path))\n",
    "            self.model.to(device)\n",
    "            self.model.eval()\n",
    "            print(\"Test model has been loaded.\")\n",
    "    \n",
    "    def get_parameters(self, param_dict, mode = 'numpy'):\n",
    "        '''\n",
    "        从 model 中剥离出参数\n",
    "        '''\n",
    "        res = dict()\n",
    "        for param in param_dict:\n",
    "            if mode == 'numpy':\n",
    "                res[param] = param_dict[param].cpu().numpy()\n",
    "            elif mode == 'list':\n",
    "                res[param] = param_dict[param].cpu().numpy().tolist()\n",
    "            else:\n",
    "                res[param] = param_dict[param]\n",
    "        return res\n",
    "    \n",
    "    def neg_sample(self):\n",
    "        '''\n",
    "        对 batch 数据进行负采样\n",
    "        无返回值\n",
    "        '''\n",
    "        self.negative_ent = 1    # 负样本实体一个\n",
    "        self.negative_rel = 0\n",
    "        self.batch_seq_size = self.config.batch_size * (1 + self.negative_ent + self.negative_rel)\n",
    "        \n",
    "        self.batch_h = np.zeros(self.batch_seq_size, dtype = np.int64)    # 容量是 batch size 的两倍，用于盛放负样本\n",
    "        self.batch_t = np.zeros(self.batch_seq_size, dtype = np.int64)\n",
    "        self.batch_r = np.zeros(self.batch_seq_size, dtype = np.int64)\n",
    "        self.batch_y = np.zeros(self.batch_seq_size, dtype = np.float32)\n",
    "\n",
    "        self.batch_h_addr = self.batch_h.__array_interface__[\"data\"][0]\n",
    "        self.batch_t_addr = self.batch_t.__array_interface__[\"data\"][0]\n",
    "        self.batch_r_addr = self.batch_r.__array_interface__[\"data\"][0]\n",
    "        self.batch_y_addr = self.batch_y.__array_interface__[\"data\"][0]\n",
    "        \n",
    "        # 这一步将数据集中实体和关系的 id 传进来\n",
    "        # print(self.batch_y)\n",
    "        self.clib.sampling(\n",
    "            self.batch_h_addr,    # 头实体 batch 的地址，传给 clib 函数的指针\n",
    "            self.batch_t_addr,\n",
    "            self.batch_r_addr,\n",
    "            self.batch_y_addr,\n",
    "            self.config.batch_size,\n",
    "            self.negative_ent,\n",
    "            self.negative_rel\n",
    "        )\n",
    "    \n",
    "    def train_batch(self):\n",
    "        '''\n",
    "        使用 self.model 训练一个 batch 的数据\n",
    "        return: 该 batch 的 loss\n",
    "        '''\n",
    "        self.model.train()\n",
    "        # 向模型喂一个 batch 的数据\n",
    "        self.model.batch_h = torch.from_numpy(self.batch_h).to(device)    # numpy 数组转为 Tensor\n",
    "        self.model.batch_t = torch.from_numpy(self.batch_t).to(device)\n",
    "        self.model.batch_r = torch.from_numpy(self.batch_r).to(device)\n",
    "        self.model.batch_y = torch.from_numpy(self.batch_y).to(device)\n",
    "        # print(self.model.batch_y)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.model()    # 会自动调用 forward() 函数\n",
    "        loss.backward()        # 误差反向传播\n",
    "        # 由于在反向传播的过程中会发生梯度消失/爆炸，因此设定阈值，当梯度大于/小于阈值时候，将梯度缩放为阈值\n",
    "        nn.utils.clip_grad_norm_(parameters = self.model.parameters(), max_norm = 0.5, norm_type = 2)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def test_batch(self, model, batch_h, batch_t, batch_r):\n",
    "        '''\n",
    "        测试一个 batch 的数据\n",
    "        batch_h: numpy array\n",
    "        batch_t: numpy array\n",
    "        batch_r: numpy array\n",
    "        return: 该 test batch 的三元组得分\n",
    "        '''\n",
    "        # model.train()  将模块设置为训练模式，使用BatchNormalizetion()和Dropout()\n",
    "        # model.eval()   将模块设置为评估模式，不使用BatchNormalization()和Dropout()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            model.batch_h = torch.from_numpy(batch_h).to(device)\n",
    "            model.batch_t = torch.from_numpy(batch_t).to(device)\n",
    "            model.batch_r = torch.from_numpy(batch_r).to(device)\n",
    "        # print(\"test batch res is:\")\n",
    "        res = model.cal_score().cpu().data.numpy()\n",
    "        # print(res.shape)\n",
    "        return res\n",
    "        \n",
    "    def validation(self, model):\n",
    "        '''\n",
    "        验证模型\n",
    "        '''\n",
    "        model.eval()\n",
    "        self.vali_h = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.vali_t = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.vali_r = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.vali_h_addr = self.vali_h.__array_interface__[\"data\"][0]    # array 的内存地址\n",
    "        self.vali_t_addr = self.vali_t.__array_interface__[\"data\"][0]\n",
    "        self.vali_r_addr = self.vali_r.__array_interface__[\"data\"][0]\n",
    "        \n",
    "        self.clib.validInit()\n",
    "        self.clib.getValidHit10.restype = ctypes.c_float\n",
    "        \n",
    "        print(\"The total number of validation triplets is %d\" % self.config.vali_num)\n",
    "        for i in range(self.config.vali_num):\n",
    "            sys.stdout.write(\"%d \\r\" % i)    # 动态打印输出\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            # 之前运行这一步服务就会\n",
    "            # 原因：self.vali_r = np.zeros(self.config.ent_num, dtype=np.int64)，写成了rel_num，以为是原代码错了，但其实没有，自作聪明的结果\n",
    "            self.clib.getValidHeadBatch(self.vali_h_addr, self.vali_t_addr, self.vali_r_addr)\n",
    "            res = self.test_batch(model, self.vali_h, self.vali_t, self.vali_r)\n",
    "            self.clib.validHead(res.__array_interface__[\"data\"][0])\n",
    "            \n",
    "            self.clib.getValidTailBatch(self.vali_h_addr, self.vali_t_addr, self.vali_r_addr)\n",
    "            res = self.test_batch(model, self.vali_h, self.vali_t, self.vali_r)\n",
    "            self.clib.validTail(res.__array_interface__[\"data\"][0])\n",
    "            \n",
    "            # 第一个 batch 的 Hits@10 res 是 0.0\n",
    "        return self.clib.getValidHit10()   # 训练时的验证步骤，需要返回 hits@10 结果\n",
    "    \n",
    "    def test(self, model):\n",
    "        self.set_model(mode = 'test')\n",
    "        # 只做链接预测实验\n",
    "        \n",
    "        print(\"The total number of test triplets is %d\" % self.config.test_num)\n",
    "\n",
    "        self.test_h = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.test_t = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.test_r = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.test_h_addr = self.test_h.__array_interface__[\"data\"][0]\n",
    "        self.test_t_addr = self.test_t.__array_interface__[\"data\"][0]\n",
    "        self.test_r_addr = self.test_r.__array_interface__[\"data\"][0]\n",
    "        \n",
    "        print(\"Testing...\")\n",
    "        for i in range(self.config.test_num):\n",
    "            sys.stdout.write(\"%d \\r\" % i)    # 动态打印输出\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            self.clib.getHeadBatch(self.test_h_addr, self.test_t_addr, self.test_r_addr)\n",
    "            res = self.test_batch(model, self.test_h, self.test_t, self.test_r)\n",
    "            self.clib.testHead(res.__array_interface__[\"data\"][0])\n",
    "\n",
    "            self.clib.getTailBatch(self.test_h_addr, self.test_t_addr, self.test_r_addr)\n",
    "            res = self.test_batch(model, self.test_h, self.test_t, self.test_r)\n",
    "            self.clib.testTail(res.__array_interface__[\"data\"][0])\n",
    "\n",
    "        self.clib.test_link_prediction()\n",
    "        print(\"Finished testing.\")\n",
    "    \n",
    "    def train_model(self):\n",
    "        if not os.path.exists(self.config.checkpoint_path):\n",
    "            os.mkdir(self.config.checkpoint_path)\n",
    "            \n",
    "        self.set_model(mode = self.config.mode)\n",
    "        \n",
    "        best_epoch = 0\n",
    "        best_hits10 = 0.0\n",
    "        best_model = self.model\n",
    "\n",
    "        epochs = tqdm(range(self.config.epoch_num))\n",
    "        \n",
    "        for epoch in epochs:\n",
    "            res = 0.0    # 用于累加本 epoch 各个 batch 的 loss\n",
    "            for batch in range(self.config.batch_num):    # 训练一个batch\n",
    "                self.neg_sample()    # 负采样\n",
    "                loss = self.train_batch()    # 训练一个 batch 为一个 step\n",
    "                # print(\"batch loss: %f\" % loss)\n",
    "                res += loss\n",
    "                \n",
    "            epochs.set_description(\"Epoch %d | loss: %f\" % (epoch, res))    # 输出进度条的描述\n",
    "            # 问题：loss到了69左右就不下降了，但是 50 epoch 后验证集正确率还是达到了 50多（但不再增长），所以应该问题不大\n",
    "            # 应该是网络比较复杂，在数据集上很快就拟合好了\n",
    "            # 验证集准确率上升很快，测试集上却没有跑出结果，应该是过拟合了\n",
    "            # 下一步是学习 ConvE 疯狂 dropout\n",
    "            \n",
    "            if (epoch + 1) % self.config.save_epoch == 0:\n",
    "                epochs.set_description(\"Epoch %d has finished, loss is %f, saving checkpoint ...\" % (epoch, res))\n",
    "                # 存储 checkpoint\n",
    "                save_path = os.path.join(self.config.checkpoint_path, self.config.dataset + \"-\" + str(epoch) + \".ckpt\")\n",
    "                torch.save(self.model.state_dict(), save_path)\n",
    "            \n",
    "            if (epoch + 1) % self.config.vali_epoch == 0:\n",
    "                epochs.set_description(\"Epoch %d has finished, loss is %f, validating ...\" % (epoch, res))\n",
    "                hits10 = self.validation(self.model)\n",
    "                print(\"hits@10 of this validation epoch is: %.8f\" % hits10)\n",
    "#                 print(\"Testing on test set ...\")\n",
    "#                 self.test(self.model)\n",
    "#                 print(\"Test result is printed on Linux shell.\")\n",
    "                \n",
    "                if hits10 > best_hits10:\n",
    "                    best_hits10 = hits10\n",
    "                    best_epoch = epoch\n",
    "                    best_model = self.model\n",
    "                    \n",
    "            # sys.exit()\n",
    "            \n",
    "        # 所有的 epoch 都循环完之后（300个），存储验证集上最优模型的网络参数和 embeddings\n",
    "        print(\"Best epoch is %d, best hit@10 of validation set is %f\" % (best_epoch, best_hits10))\n",
    "        print(\"Storing checkpoint of best result at epoch %d ...\" % (best_epoch))\n",
    "        netparam_save_path = os.path.join(self.config.checkpoint_path, self.config.dataset + \"-netparam_best\" + \".ckpt\")\n",
    "        torch.save(best_model.state_dict(), netparam_save_path)\n",
    "\n",
    "        embed_save_path = os.path.join(self.config.checkpoint_path, self.config.dataset + \"-embed_best\" + \".json\")\n",
    "        with open(embed_save_path, 'w') as f:\n",
    "            f.write(json.dumps(self.get_parameters(best_model.state_dict(), 'list')))\n",
    "        print(\"Finished Storing best model and embeddings.\")\n",
    "\n",
    "        self.test(model = best_model)    # 测试结果会输出在 Linux 终端\n",
    "\n",
    "# 训练目标：FB15K237 Hits@10 至少要0.5，MR 二三百，MRR 0.2~0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing training model...\n",
      "Training model has been initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499 has finished, loss is 17.038971, validating ...:  50%|████▉     | 499/1000 [12:46<12:51,  1.54s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 17535\n",
      "17534 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 499 has finished, loss is 17.038971, validating ...:  50%|█████     | 500/1000 [14:35<4:44:24, 34.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@10 of this validation epoch is: 0.38505846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999 has finished, loss is 15.026243, validating ...: 100%|█████████▉| 999/1000 [27:24<00:01,  1.54s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 17535\n",
      "17534 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999 has finished, loss is 15.026243, validating ...: 100%|██████████| 1000/1000 [29:17<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@10 of this validation epoch is: 0.38711149\n",
      "Best epoch is 999, best hit@10 of validation set is 0.387111\n",
      "Storing checkpoint of best result at epoch 999 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Storing best model and embeddings.\n",
      "Fetching model for test...\n",
      "Test model has been loaded.\n",
      "The total number of test triplets is 20466\n",
      "Testing...\n",
      "Finished testing.\n"
     ]
    }
   ],
   "source": [
    "runner = Runner(con, conv3d)\n",
    "if runner.config.mode == 'train':\n",
    "    runner.train_model()\n",
    "else:\n",
    "    runner.test(runner.model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch(py36)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
